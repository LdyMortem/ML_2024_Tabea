{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542aaa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e17748",
   "metadata": {},
   "source": [
    "$\\textbf{Reading in Data and Cleaning}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7458e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 Condition                    Condition_Desc     Price  \\\n",
      "0              0      Used            mint!!! very low miles  $11,412    \n",
      "1              1      Used                 Perfect condition  $17,200    \n",
      "2              2      Used                               NaN   $3,872    \n",
      "3              3      Used  CLEAN TITLE   READY TO RIDE HOME   $6,575    \n",
      "4              4      Used                               NaN  $10,000    \n",
      "...          ...       ...                               ...       ...   \n",
      "7488        7488      Used                               NaN   $3,900    \n",
      "7489        7489      Used                               NaN   $8,900    \n",
      "7490        7490      Used                               NaN   $7,800    \n",
      "7491        7491      Used                               NaN   $7,900    \n",
      "7492        7492      Used                               NaN  $12,970    \n",
      "\n",
      "                                   Location  Model_Year Mileage  \\\n",
      "0          McHenry, Illinois, United States      2013.0  16,000   \n",
      "1        Fort Recovery, Ohio, United States      2016.0      60   \n",
      "2          Chicago, Illinois, United States      1970.0  25,763   \n",
      "3       Green Bay, Wisconsin, United States      2009.0  33,142   \n",
      "4       West Bend, Wisconsin, United States      2012.0  17,800   \n",
      "...                                     ...         ...     ...   \n",
      "7488  Raymond, New Hampshire, United States      2004.0  23,681   \n",
      "7489  Raymond, New Hampshire, United States      2013.0   5,821   \n",
      "7490  Raymond, New Hampshire, United States      2011.0  48,616   \n",
      "7491  Raymond, New Hampshire, United States      2014.0   6,185   \n",
      "7492    Scott City, Missouri, United States      2016.0     448   \n",
      "\n",
      "     Exterior_Color             Make  \\\n",
      "0             Black  Harley-Davidson   \n",
      "1             Black  Harley-Davidson   \n",
      "2       Silver/Blue              BMW   \n",
      "3               Red  Harley-Davidson   \n",
      "4              Blue  Harley-Davidson   \n",
      "...             ...              ...   \n",
      "7488          Black  Harley-Davidson   \n",
      "7489          Black           Suzuki   \n",
      "7490            Red              BMW   \n",
      "7491       TWO TONE           Yamaha   \n",
      "7492           Gray  Harley-Davidson   \n",
      "\n",
      "                                        Warranty  ... Vehicle_Title    OBO  \\\n",
      "0                                    Unspecified  ...           NaN  False   \n",
      "1               Vehicle has an existing warranty  ...           NaN  False   \n",
      "2     Vehicle does NOT have an existing warranty  ...           NaN  False   \n",
      "3                                            NaN  ...           NaN  False   \n",
      "4                                    NO WARRANTY  ...           NaN  False   \n",
      "...                                          ...  ...           ...    ...   \n",
      "7488                                         NaN  ...           NaN   True   \n",
      "7489                                         NaN  ...           NaN   True   \n",
      "7490                                         NaN  ...           NaN   True   \n",
      "7491                                         NaN  ...           NaN   True   \n",
      "7492            Vehicle has an existing warranty  ...           NaN  False   \n",
      "\n",
      "     Feedback_Perc  Watch_Count  N_Reviews   Seller_Status Vehicle_Tile  \\\n",
      "0              8.1          NaN       2427  Private Seller        Clear   \n",
      "1              100           17        657  Private Seller        Clear   \n",
      "2              100          NaN        136             NaN        Clear   \n",
      "3              100          NaN       2920          Dealer        Clear   \n",
      "4              100           13        271           OWNER        Clear   \n",
      "...            ...          ...        ...             ...          ...   \n",
      "7488           4.7          NaN      12409          Dealer      Salvage   \n",
      "7489           4.7          NaN      12409          Dealer      Salvage   \n",
      "7490           4.7          NaN      12409          Dealer      Salvage   \n",
      "7491           4.7          NaN      12409          Dealer      Salvage   \n",
      "7492           100          NaN          4          Dealer        Clear   \n",
      "\n",
      "      Auction Buy_Now Bid_Count  \n",
      "0        True   False      28.0  \n",
      "1        True    True       0.0  \n",
      "2        True   False      26.0  \n",
      "3        True   False      11.0  \n",
      "4        True    True       0.0  \n",
      "...       ...     ...       ...  \n",
      "7488    False   False       NaN  \n",
      "7489    False   False       NaN  \n",
      "7490    False   False       NaN  \n",
      "7491    False   False       NaN  \n",
      "7492    False   False       NaN  \n",
      "\n",
      "[7493 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"MotorcycleData.csv\", delimiter = \",\")\n",
    "print(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8298c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "String attributes not supported yet, sorry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33420/1317991456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marff_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_.arff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_raw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marff_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_raw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/io/arff/_arffread.py\u001b[0m in \u001b[0;36mloadarff\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mofile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only close what we opened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/io/arff/_arffread.py\u001b[0m in \u001b[0;36m_loadarff\u001b[0;34m(ofile)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;31m# How to support string efficiently ? Ideally, we should know the max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# size of the string before allocating the numpy array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"String attributes not supported yet, sorry\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: String attributes not supported yet, sorry"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "arff_file = arff.loadarff('dataset_.arff')\n",
    "df_raw1 = pd.DataFrame(arff_file[0])\n",
    "print(df_raw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available columns: \", df_raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc341b61",
   "metadata": {},
   "source": [
    "$\\textbf{Potentially useful columns:}$ \n",
    "\n",
    "condition, \n",
    "\n",
    "price, \n",
    "\n",
    "location (use longitude and latitude), \n",
    "\n",
    "model_year (use relative year to today), \n",
    "\n",
    "mileage, \n",
    "\n",
    "make, \n",
    "\n",
    "(warranty, Too many NaNs)\n",
    "\n",
    "vehicle_title, \n",
    "\n",
    "seller_status, \n",
    "\n",
    "Vehicle_Tile,\n",
    "\n",
    "auction = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ada54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[df_raw[\"Auction\"] == False , [\"Condition\", \"OBO\", \"Price\", \"Location\", \"Model_Year\", \"Mileage\", \"Make\", \"Vehicle_Title\", \"Seller_Status\", \"Auction\", \"Vehicle_Tile\"]]\n",
    "df = df[df[\"Vehicle_Tile\"] == \"Clear\"]\n",
    "df['Loc'] = df[\"Location\"].str.split(',').str[0] + \",\" + df[\"Location\"].str.split(',').str[1]\n",
    "df = df.drop(columns = 'Location')\n",
    "#df = df[df[\"OBO\"] == False]\n",
    "\n",
    "df[\"Seller_Status\"].unique()\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1447528f",
   "metadata": {},
   "source": [
    "Cities from: https://simplemaps.com/data/us-cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- SELECT ONLY THE TOP 10 CITIES OF EACH STATE -----------\n",
    "#df_big_cities = df_cities.merge(df_cities[['city', 'state_name','population']].drop_duplicates().groupby('state_name').head(10))\n",
    "#df_big_cities['Loc'] = df_big_cities[\"city\"] + \", \" + df_big_cities[\"state_name\"]\n",
    "#df_big_cities = df_big_cities.drop(columns = 'city')\n",
    "#df_big_cities = df_big_cities.drop(columns = 'state_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8272f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = pd.read_csv(\"uscities.csv\", delimiter = \",\", usecols = [\"city\", \"state_name\", \"lat\", \"lng\", \"population\", \"ranking\"])\n",
    "df_cities['Loc'] = df_cities[\"city\"] + \", \" + df_cities[\"state_name\"]\n",
    "df_cities = df_cities.drop(columns = 'city')\n",
    "df_cities = df_cities.drop(columns = 'state_name')\n",
    "#print(df_cities)\n",
    "df = pd.merge(df, df_cities, how = \"left\", on=[\"Loc\"])\n",
    "df[\"lat\"].fillna(value=df[\"lat\"].mean(), inplace=True) \n",
    "df[\"lng\"].fillna(value=df[\"lng\"].mean(), inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb066c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"lng\"] > -140]\n",
    "df = df[df[\"lat\"] > 20]\n",
    "sns.scatterplot(x = df[\"lng\"], y = df[\"lat\"])\n",
    "\n",
    "\n",
    "#df_cleaned = df.loc[df_raw[\"Auction\"] == False, [\"Condition\", \"Price\", \"Location\", \"Model_Year\", \"Mileage\", \"Make\", \"Warranty\", \"Vehicle_Title\", \"OBO\", \"Seller_Status\", \"Auction\"]]\n",
    "#df[\"Price\"].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb72500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Price\"] = df[\"Price\"].replace(\"[$,]\", \"\", regex=True).astype(int)\n",
    "df[\"Mileage\"] = df[\"Mileage\"].replace(\",\", \"\", regex=True).astype(float)\n",
    "df[\"Model_Year\"] = df[\"Model_Year\"].astype(int)\n",
    "df[\"Mileage\"].fillna(value=df[\"Mileage\"].mean(), inplace=True) \n",
    "df[\"Mileage\"] = df[\"Mileage\"].astype(int)\n",
    "df = df[df[\"Mileage\"] < 100000]\n",
    "df[\"population\"].fillna(value=df[\"population\"].mean(), inplace=True) \n",
    "df[\"population\"] = df[\"population\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b639e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Make'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['Condition'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['Seller_Status'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['OBO'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663caead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Seller_Status_Private Seller\"] = df[\"Seller_Status_Private Seller\"] + df[\"Seller_Status_Private Owner\"] + df[\"Seller_Status_Ricky\"] \n",
    "+ df[\"Seller_Status_OWNER\"] \n",
    "+ df[\"Seller_Status_owner\"] + df[\"Seller_Status_Owner\"]\n",
    "+ df[\"Seller_Status_Peter Root\"]\n",
    "+ df[\"Seller_Status_JOHNNY RAY RICHLAND    TRIKE ON AMERICA\"] + df[\"Seller_Status_onwer\"]\n",
    "+ df[\"Seller_Status_original owners son\"]\n",
    "+ df[\"Seller_Status_First Owner\"] + df[\"Seller_Status_Original Owner\"]\n",
    "+  df[\"Seller_Status_Private owner\"]\n",
    "\n",
    "df[\"Seller_Status_Dealer\"] = df[\"Seller_Status_Dealer\"] + df[\"Seller_Status_Carrigan Motor Group\"] + df[\"Seller_Status_SHORELINE HARLEY -  DAVIDSON\"]\n",
    "+ df[\"Seller_Status_factory\"] + df[\"Seller_Status_manufacturer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Make_Harley-Davidson\"] = df[\"Make_Harley-Davidson\"] + df[\"Make_Harley-Davidson®\"] + df[\"Make_American Classic Motors\"]\n",
    "df[\"Make_Honda\"] = df[\"Make_Honda\"] + df[\"Make_Honda®\"] \n",
    "df[\"Make_Can-Am\"] = df[\"Make_Can-Am\"] + df[\"Make_Can-Am®\"]\n",
    "df[\"Make_Custom\"] = df[\"Make_Custom Built Motorcycles\"] +  df[\"Make_American Ironhorse\"]  + df[\"Make_American IronHorse\"] + df[\"Make_Other\"] + df[\"Make_Custom\"] + df[\"Make_Other Makes\"]\n",
    "+ df[\"Make_BSA\"] +  df[\"Make_BETA\"]  + df[\"Make_Benelli\"] + df[\"Make_Big Bear Choppers\"] + df[\"Make_Bimota\"] + df[\"Make_Boss Hoss\"]\n",
    "+ df[\"Make_Bourget\"] +  df[\"Make_Cushman\"]  + df[\"Make_Husqvarna\"] + df[\"Make_Hyosung\"] + df[\"Make_Norton\"] + df[\"Make_Piaggio\"] + df[\"Make_Ultimate\"] + df[\"Make_Wild West\"]\n",
    "\n",
    "df[\"Make_BMW\"] = df[\"Make_BMW\"] + df[\"Make_Bmw Motorcycle\"] + df[\"Make_ADVANTAGE\"]\n",
    "df[\"Make_Polaris\"] = df[\"Make_POLARIS\"] + df[\"Make_Polaris®\"] + df[\"Make_Polaris\"]  + df[\"Make_Slingshot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a9205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(columns = [\"Vehicle_Title\", \"Auction\", \"Vehicle_Tile\", \"Loc\", \"ranking\", \"Seller_Status_Private Owner\", \"Seller_Status_Ricky\", \"Seller_Status_OWNER\" \n",
    "                                , \"Seller_Status_owner\" , \"Seller_Status_Owner\"\n",
    "                                , \"Seller_Status_Peter Root\" \n",
    "                                , \"Seller_Status_JOHNNY RAY RICHLAND    TRIKE ON AMERICA\" , \"Seller_Status_onwer\"\n",
    "                                , \"Seller_Status_original owners son\"\n",
    "                                , \"Seller_Status_First Owner\" , \"Seller_Status_Original Owner\"\n",
    "                                , \"Seller_Status_Private owner\", \"Seller_Status_Carrigan Motor Group\" , \"Seller_Status_SHORELINE HARLEY -  DAVIDSON\"\n",
    "                                , \"Seller_Status_factory\" , \"Seller_Status_manufacturer\", \"Make_Harley-Davidson®\", \"Make_American Classic Motors\", \"Make_Honda®\"\n",
    "                                , \"Make_Can-Am®\", \"Make_Custom Built Motorcycles\" , \"Make_American Ironhorse\" , \"Make_American IronHorse\"\n",
    "                                , \"Make_Other\" , \"Make_Custom\" , \"Make_Other Makes\",\"Make_Bmw Motorcycle\" , \"Make_ADVANTAGE\", \"Make_POLARIS\", \"Make_Polaris®\",\"Make_Slingshot\"\n",
    "                                , \"Make_BSA\" ,  \"Make_BETA\", \"Make_Benelli\" , \"Make_Big Bear Choppers\" , \"Make_Bimota\" , \"Make_Boss Hoss\"\n",
    "                                , \"Make_Bourget\" ,  \"Make_Cushman\"  , \"Make_Husqvarna\" , \"Make_Hyosung\" , \"Make_Norton\" ,\"Make_Piaggio\" \n",
    "                                , \"Make_Ultimate\" , \"Make_Wild West\"\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfb996",
   "metadata": {},
   "source": [
    "$\\textbf{Looking at the variables}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.hist(alpha=0.8, figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b02bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from pandas.plotting import scatter_matrix\n",
    "#scatter_matrix(df_cleaned, alpha=0.8, figsize=(30, 30), s=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5129c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop('Price', axis=1)  # Replace 'target_column' with your actual target column name\n",
    "y = df_cleaned['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(X.corr(), annot=True, square=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the target variable using logarithm\n",
    "y_log = np.log(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for regression)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = model.predict(X_test)\n",
    "\n",
    "# Transform the predictions back to the original scale\n",
    "y_pred = np.exp(y_pred_log)\n",
    "y_test = np.exp(y_test_log)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "#file_path = 'motorcycles.csv'\n",
    "#df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the features (X) and the target (y)\n",
    "#X = df[['brand', 'model', 'year', 'mileage', 'condition']]  # Replace with your actual feature columns\n",
    "#y = df['price']  # Target column\n",
    "\n",
    "# Encode categorical variables (if any)\n",
    "#X = pd.get_dummies(X, columns=['brand', 'model', 'condition'], drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=40)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE: {mse_rf}\")\n",
    "print(y_test, y_pred_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with XGBoost\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MSE: {mse_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ed1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)  # You can choose the number of neighbors (k)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print classification report\n",
    "#print(\"Classification Report:\")\n",
    "#print(classification_report(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(y_test, y_pred)\n",
    "# Print confusion matrix\n",
    "#print(\"Confusion Matrix:\")\n",
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccc2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
